{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harr1\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 229198 entries, 0 to 229197\n",
      "Data columns (total 31 columns):\n",
      "OBJECTID           229198 non-null int64\n",
      "ROUNDID            229198 non-null int64\n",
      "MISSIONID          229198 non-null object\n",
      "REGION_NAME        229198 non-null object\n",
      "ISLAND             229198 non-null object\n",
      "SITEVISITID        229198 non-null int64\n",
      "SITE               229198 non-null object\n",
      "LATITUDE           229184 non-null float64\n",
      "LONGITUDE          229184 non-null float64\n",
      "REEF_ZONE          229198 non-null object\n",
      "DEPTH_BIN          224864 non-null object\n",
      "MIN_Z_M            209939 non-null float64\n",
      "MAX_Z_M            209939 non-null float64\n",
      "DATE_              229198 non-null object\n",
      "OBS_YEAR           229198 non-null int64\n",
      "LPITRANSECTRUN     229198 non-null int64\n",
      "DIVER              229198 non-null object\n",
      "MINDEPTH           180610 non-null float64\n",
      "MAXDEPTH           182488 non-null float64\n",
      "METHODCODE         229198 non-null int64\n",
      "CALIBRATION        99078 non-null float64\n",
      "TRANNUM            229198 non-null int64\n",
      "LPI_SEG            229198 non-null object\n",
      "BENTHICCODE        229198 non-null object\n",
      "FAMILY             112086 non-null object\n",
      "GENUS              112086 non-null object\n",
      "CATEGORY_GENUS     229198 non-null object\n",
      "BENTHICNAME        229198 non-null object\n",
      "BENTHICCATEGORY    229198 non-null object\n",
      "COMMON_NAME        229198 non-null object\n",
      "COUNT              229198 non-null int64\n",
      "dtypes: float64(7), int64(8), object(16)\n",
      "memory usage: 40.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\harr1\\Downloads\\V0_BENT_LPI.csv')                                               #######\n",
    "print (df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop columns that are not important                                                                                                       \n",
    "df = df.drop(['MINDEPTH', 'MAXDEPTH', 'CALIBRATION', 'MIN_Z_M', 'MAX_Z_M', 'OBJECTID', 'ROUNDID',\n",
    "             'TRANNUM', 'LPI_SEG', 'METHODCODE'], axis=1)\n",
    "#No information about how 2009 data collected, so drop this year from dataset\n",
    "df = df[df['OBS_YEAR']!=2009]\n",
    "#Only interested in corals, so eliminate anything that is not a coral\n",
    "df = df[df['BENTHICCATEGORY'] == 'CORL']\n",
    "#Drop nulls\n",
    "df= df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummies for island, region, family, diver, and reef zone                                         \n",
    "df = pd.concat([df, df['FAMILY'].str.get_dummies(sep=',')], axis=1)\n",
    "df = pd.concat([df, df['ISLAND'].str.get_dummies(sep=',')], axis=1)\n",
    "df = pd.concat([df, df['REEF_ZONE'].str.get_dummies(sep=',')], axis=1)\n",
    "df = pd.concat([df, df['REGION_NAME'].str.get_dummies(sep=',')], axis=1)\n",
    "df = pd.concat([df, df['DIVER'].str.get_dummies(sep=',')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date from dd-ABREV-yyyy to yyyymmdd                                                                     ####\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "df['Date']= [datetime.strptime(x, '%d-%b-%y').strftime('%Y-%m-%d') for x in df['DATE_']]\n",
    "\n",
    "df['Month'] = [datetime.strptime(x, '%Y-%m-%d').strftime('%Y-%m') for x in df['Date']]\n",
    "\n",
    "for x in df['Date']:\n",
    "    x.replace(\"-\", \"\")\n",
    "    \n",
    "for y in df['Month']:\n",
    "    y.replace(\"-\", \"\")\n",
    "    \n",
    "\n",
    "#Sort values as they are out of order in the original dataframe\n",
    "df_sorted = df.sort_values('Date')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the Transects taken per day\n",
    "#Calculate the total number of corals found per day\n",
    "\n",
    "df_sorted['Transect/day'] = df_sorted['LPITRANSECTRUN'].groupby(df_sorted['Date']).transform('nunique')                         ######\n",
    "df_sorted['Coral/day'] = df_sorted['COUNT'].groupby(df_sorted['Date']).transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harr1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\harr1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Transforming data based on samples taken during observations                                     \n",
    "\n",
    "# Since 2005-2008 data was collected every 50cm and 2010-2012 data collected every 20cm, we need to standardize the data\n",
    "# 2005-2008 data multiplied by 2.5 as there were 2.5X fewer observations made per transect. Data divided by number \n",
    "# of transects taken per day to standardize how many corals found per meter\n",
    "\n",
    "df_2005 = df_sorted[df_sorted['Date']<='2008-12-31']\n",
    "df_2010 = df_sorted[df_sorted['Date']>'2009-12-31']\n",
    "\n",
    "\n",
    "df_2005['Coral/m']= (((df_2005['Coral/day']*2.5)/df_2005['Transect/day'])/25)\n",
    "df_2010['Coral/m']= (((df_2010['Coral/day'])/df_2010['Transect/day'])/25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         0.875000\n",
      "98        0.875000\n",
      "100       0.875000\n",
      "105       0.875000\n",
      "11        0.875000\n",
      "96        0.875000\n",
      "8         0.875000\n",
      "5         0.875000\n",
      "4         0.875000\n",
      "3         0.875000\n",
      "10        0.875000\n",
      "93        1.550000\n",
      "92        1.550000\n",
      "89        1.550000\n",
      "87        1.550000\n",
      "84        1.550000\n",
      "83        1.550000\n",
      "81        1.550000\n",
      "79        1.550000\n",
      "77        1.550000\n",
      "76        1.550000\n",
      "55        1.550000\n",
      "49        1.550000\n",
      "94        1.550000\n",
      "47        1.550000\n",
      "52        1.550000\n",
      "44        1.550000\n",
      "74        1.150000\n",
      "71        1.150000\n",
      "58        1.150000\n",
      "            ...   \n",
      "211918    1.266667\n",
      "211865    1.266667\n",
      "211790    1.266667\n",
      "211864    1.266667\n",
      "211855    1.266667\n",
      "211797    1.266667\n",
      "211798    1.266667\n",
      "211799    1.266667\n",
      "211800    1.266667\n",
      "211805    1.266667\n",
      "211806    1.266667\n",
      "211812    1.266667\n",
      "211816    1.266667\n",
      "211822    1.266667\n",
      "211824    1.266667\n",
      "211825    1.266667\n",
      "211832    1.266667\n",
      "211833    1.266667\n",
      "211834    1.266667\n",
      "211837    1.266667\n",
      "211838    1.266667\n",
      "211839    1.266667\n",
      "211840    1.266667\n",
      "211841    1.266667\n",
      "211842    1.266667\n",
      "211851    1.266667\n",
      "211852    1.266667\n",
      "211854    1.266667\n",
      "211863    1.266667\n",
      "211880    1.266667\n",
      "Name: Coral/m, Length: 49846, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Add the transformed data back into the sorted dataframe\n",
    "df_sorted= pd.concat([df_2005, df_2010], axis=0)\n",
    "print (df_sorted['Coral/m'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['OBS_YEAR',\n",
    "           'LATITUDE', \n",
    "           'LONGITUDE', \n",
    "           #Reef zone\n",
    "           'Forereef', 'Lagoon', 'Protected Slope', 'Backreef',\n",
    "           #Families\n",
    "           'Acroporidae', 'Agariciidae', 'Pocilloporidae', 'Faviidae', 'Siderastreidae',\n",
    " 'Poritidae', 'Merulinidae', 'Milleporidae', 'Dendrophylliidae', 'Fungiidae',\n",
    " 'Mussidae', 'Oculinidae', 'Pectiniidae', 'Helioporidae', 'Astrocoeniidae',\n",
    " 'Caryophylliidae', 'Stylasteridae',\n",
    "           #Divers\n",
    "           'BVA', 'JCK', 'JSH', 'CLR', 'RDW', 'RO',\n",
    "           #Islands\n",
    "           'Guam', 'Santa Rosa', 'Wake', 'Hawaii', 'Kauai', 'Kaula', 'Lanai',\n",
    "       'Lehua', 'Maui', 'Molokai', 'Niihau', 'Oahu', 'French Frigate',\n",
    "       'Kure', 'Laysan', 'Lisianski', 'Maro', 'Midway', 'Necker',\n",
    "       'Pearl & Hermes', 'Baker', 'Howland', 'Jarvis', 'Johnston',\n",
    "       'Kingman', 'Palmyra', 'Ofu & Olosega', 'Rose', 'Swains', 'Tau',\n",
    "       'Tutuila', 'Agrihan', 'Aguijan', 'Alamagan', 'Asuncion',\n",
    "       'Farallon de Pajaros', 'Guguan', 'Maug', 'Pagan', 'Rota', 'Saipan',\n",
    "       'Sarigan', 'Tinian',\n",
    "           #Regions\n",
    "           'Mariana Archipelago', 'Pacific Remote Island Areas',\n",
    "       'Main Hawaiian Islands', 'Northwestern Hawaiian Islands',\n",
    "       'American Samoa'\n",
    "          ]]\n",
    "target = df_sorted['Coral/m']\n",
    "           \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names=['OBS_YEAR',\n",
    "           'LATITUDE', \n",
    "           'LONGITUDE', \n",
    "           #Reef zone\n",
    "           'Forereef', 'Lagoon', 'Protected Slope', 'Backreef',\n",
    "           #Families\n",
    "           'Acroporidae', 'Agariciidae', 'Pocilloporidae', 'Faviidae', 'Siderastreidae',\n",
    " 'Poritidae', 'Merulinidae', 'Milleporidae', 'Dendrophylliidae', 'Fungiidae',\n",
    " 'Mussidae', 'Oculinidae', 'Pectiniidae', 'Helioporidae', 'Astrocoeniidae',\n",
    " 'Caryophylliidae', 'Stylasteridae',\n",
    "           #Divers\n",
    "           'BVA', 'JCK', 'JSH', 'CLR', 'RDW', 'RO',\n",
    "           #Islands\n",
    "           'Guam', 'Santa Rosa', 'Wake', 'Hawaii', 'Kauai', 'Kaula', 'Lanai',\n",
    "       'Lehua', 'Maui', 'Molokai', 'Niihau', 'Oahu', 'French Frigate',\n",
    "       'Kure', 'Laysan', 'Lisianski', 'Maro', 'Midway', 'Necker',\n",
    "       'Pearl & Hermes', 'Baker', 'Howland', 'Jarvis', 'Johnston',\n",
    "       'Kingman', 'Palmyra', 'Ofu & Olosega', 'Rose', 'Swains', 'Tau',\n",
    "       'Tutuila', 'Agrihan', 'Aguijan', 'Alamagan', 'Asuncion',\n",
    "       'Farallon de Pajaros', 'Guguan', 'Maug', 'Pagan', 'Rota', 'Saipan',\n",
    "       'Sarigan', 'Tinian',\n",
    "           #Regions\n",
    "           'Mariana Archipelago', 'Pacific Remote Island Areas',\n",
    "       'Main Hawaiian Islands', 'Northwestern Hawaiian Islands',\n",
    "       'American Samoa'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harr1\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandForest= ensemble.RandomForestRegressor()\n",
    "\n",
    "RandForest.fit(data,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OBS_YEAR                       3.520281e-01\n",
       "LATITUDE                       2.925017e-01\n",
       "LONGITUDE                      1.963834e-01\n",
       "Lanai                          2.381714e-02\n",
       "Pacific Remote Island Areas    1.982375e-02\n",
       "Lagoon                         1.851463e-02\n",
       "Poritidae                      1.372094e-02\n",
       "Pearl & Hermes                 1.268406e-02\n",
       "CLR                            1.027174e-02\n",
       "Niihau                         7.735686e-03\n",
       "Tau                            6.666781e-03\n",
       "Wake                           5.753583e-03\n",
       "JCK                            3.139494e-03\n",
       "Forereef                       2.982991e-03\n",
       "Oahu                           2.822317e-03\n",
       "Swains                         2.694338e-03\n",
       "Baker                          2.616932e-03\n",
       "Tutuila                        2.544593e-03\n",
       "BVA                            2.120030e-03\n",
       "Acroporidae                    1.969020e-03\n",
       "American Samoa                 1.398802e-03\n",
       "Pocilloporidae                 1.335854e-03\n",
       "Laysan                         1.260078e-03\n",
       "Maug                           1.114105e-03\n",
       "Palmyra                        1.082666e-03\n",
       "Kingman                        1.045844e-03\n",
       "Backreef                       1.019638e-03\n",
       "Ofu & Olosega                  8.904452e-04\n",
       "Rota                           7.314498e-04\n",
       "RDW                            7.144339e-04\n",
       "                                   ...     \n",
       "Siderastreidae                 1.459463e-04\n",
       "Guam                           1.392372e-04\n",
       "Main Hawaiian Islands          1.356392e-04\n",
       "Mussidae                       1.271818e-04\n",
       "Howland                        1.268401e-04\n",
       "Guguan                         1.147724e-04\n",
       "Rose                           9.118497e-05\n",
       "Oculinidae                     7.881014e-05\n",
       "Lisianski                      7.785235e-05\n",
       "Dendrophylliidae               7.006046e-05\n",
       "Aguijan                        6.817431e-05\n",
       "Milleporidae                   4.707906e-05\n",
       "Jarvis                         3.764059e-05\n",
       "Helioporidae                   3.275015e-05\n",
       "JSH                            2.376160e-05\n",
       "Agrihan                        2.302897e-05\n",
       "Saipan                         2.120790e-05\n",
       "Farallon de Pajaros            1.740324e-05\n",
       "Kaula                          1.280318e-05\n",
       "Stylasteridae                  1.059809e-05\n",
       "Alamagan                       9.337254e-06\n",
       "Mariana Archipelago            7.010648e-06\n",
       "Necker                         4.747502e-06\n",
       "Asuncion                       3.433697e-06\n",
       "Pectiniidae                    2.784773e-06\n",
       "Johnston                       2.235071e-06\n",
       "Caryophylliidae                2.185558e-07\n",
       "Santa Rosa                     1.132454e-08\n",
       "RO                             0.000000e+00\n",
       "Astrocoeniidae                 0.000000e+00\n",
       "Length: 78, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "RandForest.feature_importances_\n",
    "RandForest_ft_series = pd.Series(data=RandForest.feature_importances_, index=data.columns)\n",
    "###################################\n",
    "sorted_series = RandForest_ft_series.sort_values(ascending = False)\n",
    "sorted_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressions: NW Hawaiian vs Pacific Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Necker' 'French Frigate' 'Maro' 'Laysan' 'Pearl & Hermes' 'Midway'\n",
      " 'Kure' 'Lisianski']\n",
      "['BVA' 'EEK' 'CLR' 'PSV' 'RDW']\n"
     ]
    }
   ],
   "source": [
    "df_NWHI= df_sorted[df_sorted['REGION_NAME']=='Northwestern Hawaiian Islands']\n",
    "\n",
    "print(df_NWHI['ISLAND'].unique())\n",
    "print(df_NWHI['DIVER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation: \n",
      " [-4.38728201e+22 -3.38878496e-02  3.06259507e-01  3.89589451e-01\n",
      " -9.36534916e-01  1.92574172e-01 -8.58611213e+00 -2.75823827e+01\n",
      " -7.49485056e-02 -3.97902225e-02]\n",
      "Mean: -4.3872820097818003e+21\n",
      "std: 1.31618460293454e+22\n",
      "Coefficients: \n",
      " [-6.09749680e+00 -2.42887025e+00 -1.30053692e+00 -3.12674800e+11\n",
      " -3.12674800e+11 -3.12674800e+11 -3.12674800e+11 -3.12674800e+11\n",
      " -3.12674800e+11 -3.12674800e+11 -3.12674800e+11 -2.92440583e+11\n",
      " -2.92440583e+11 -2.92440583e+11 -2.92440583e+11 -2.92440583e+11]\n",
      "Intercept: \n",
      " 605115385026.6493\n",
      "Regression score: \n",
      " 0.6768727120267547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_NW = df_NWHI[[\n",
    "                'LATITUDE', \n",
    "                'LONGITUDE', \n",
    "    'OBS_YEAR',\n",
    "    'French Frigate', 'Kure', 'Laysan', 'Lisianski', 'Maro', 'Midway', 'Necker', 'Pearl & Hermes',\n",
    "    'BVA', 'EEK', 'CLR', 'RDW', 'PSV']]\n",
    "\n",
    "target_NW = df_NWHI['Coral/m']\n",
    "\n",
    "data_NW_names=['LATITUDE', \n",
    "                'LONGITUDE', \n",
    "    'OBS_YEAR',\n",
    "    'French Frigate', 'Kure', 'Laysan', 'Lisianski', 'Maro', 'Midway', 'Necker', 'Pearl & Hermes',\n",
    "    'BVA', 'EEK', 'CLR', 'RDW', 'PSV']\n",
    "############################################\n",
    "\n",
    "regr_NW = linear_model.LinearRegression()\n",
    "\n",
    "regr_NW.fit(data_NW, target_NW)\n",
    "\n",
    "cross_variable_NW=cross_val_score(regr_NW, data_NW, target_NW, cv=10)\n",
    "print('Cross Validation: \\n', cross_variable_NW)\n",
    "print ('Mean:', np.mean(cross_variable_NW))\n",
    "print ('std:',np.std(cross_variable_NW))\n",
    "print('Coefficients: \\n', regr_NW.coef_)\n",
    "print('Intercept: \\n', regr_NW.intercept_)\n",
    "print ('Regression score: \\n', regr_NW.score(data_NW,target_NW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wake' 'Johnston' 'Howland' 'Baker' 'Jarvis' 'Palmyra' 'Kingman']\n",
      "['VB' 'BVA' 'CLR' 'NNP' 'RDW']\n"
     ]
    }
   ],
   "source": [
    "df_PRI= df_sorted[df_sorted['REGION_NAME']=='Pacific Remote Island Areas']\n",
    "\n",
    "print(df_PRI['ISLAND'].unique())\n",
    "print(df_PRI['DIVER'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation: \n",
      " [-0.03057147  0.25071588  0.04942736 -0.42756215 -0.26564785 -1.04707388\n",
      " -0.06624968 -3.47853977 -0.05161445  0.03885202]\n",
      "Mean: -0.5028264002257709\n",
      "std: 1.048638908818488\n",
      "Coefficients: \n",
      " [-5.57170899e+00 -3.52935278e+00 -1.12264010e-01  1.08018391e+03\n",
      " -2.36862989e+02 -2.33684835e+02 -1.81871812e+02 -1.20156660e+02\n",
      " -1.52839884e+02 -1.54767732e+02 -6.91184029e-02 -4.12175581e-01\n",
      " -1.92773035e-01  3.78451793e-01  2.95615227e-01]\n",
      "Intercept: \n",
      " -157.35397872222566\n",
      "Regression score: \n",
      " 0.19507201258467488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_PRI = df_PRI[[\n",
    "                'LATITUDE', \n",
    "                'LONGITUDE',\n",
    "    'OBS_YEAR',\n",
    "                'Wake', 'Baker', 'Howland', 'Jarvis', 'Johnston', 'Kingman', 'Palmyra',\n",
    "    'VB',  'BVA', 'CLR', 'NNP', 'RDW'       \n",
    "          ]]\n",
    "target_PRI = df_PRI['Coral/m']\n",
    "\n",
    "data_PRI_names = ['LATITUDE', \n",
    "                'LONGITUDE',\n",
    "    'OBS_YEAR',\n",
    "                'Wake', 'Baker', 'Howland', 'Jarvis', 'Johnston', 'Kingman', 'Palmyra',\n",
    "    'VB',  'BVA', 'CLR', 'NNP', 'RDW'       \n",
    "          ]\n",
    "############################################\n",
    "\n",
    "regr_PRI = linear_model.LinearRegression()\n",
    "\n",
    "regr_PRI.fit(data_PRI, target_PRI)\n",
    "\n",
    "cross_variable_PRI=cross_val_score(regr_PRI, data_PRI, target_PRI, cv=10)\n",
    "print('Cross Validation: \\n', cross_variable_PRI)\n",
    "print ('Mean:', np.mean(cross_variable_PRI))\n",
    "print ('std:',np.std(cross_variable_PRI))\n",
    "print('Coefficients: \\n', regr_PRI.coef_)\n",
    "print('Intercept: \\n', regr_PRI.intercept_)\n",
    "print ('Regression score: \\n', regr_PRI.score(data_PRI,target_PRI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Random forest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harr1\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 s ± 21.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Cross Validation: \n",
      " [-0.81958368 -0.15894791 -0.20083773 -0.12036037 -0.51318119 -1.19605777\n",
      " -1.02072297 -1.25363443 -2.4113888  -0.51248311]\n",
      "Mean: -0.8207197970533763\n",
      "std: 0.6633862451292123\n",
      "Regression score: \n",
      " 0.9217930884896011\n"
     ]
    }
   ],
   "source": [
    "#Random forest for all data\n",
    "RandForest= ensemble.RandomForestRegressor()\n",
    "\n",
    "%timeit RandForest.fit(data,target)\n",
    "\n",
    "cross_variable=cross_val_score(RandForest, data, target, cv=10)\n",
    "print('Cross Validation: \\n', cross_variable)\n",
    "print ('Mean:', np.mean(cross_variable))\n",
    "print ('std:',np.std(cross_variable))\n",
    "print ('Regression score: \\n', RandForest.score(data,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MLP so slow! Ran with 4,25 hidden layers and the score was only .064. That run was 15+17 s per loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 26.29 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "25.1 s ± 38.2 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Import the model.\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(25,100))\n",
    "%timeit mlp.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3948459738228207"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross scores: [-0.3204384  -2.7196599  -7.14702305 -2.86858487 -1.49341705]\n",
      "Stdev: 2.3109671273373995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_score = cross_val_score(mlp, data, target, cv=5)\n",
    "print('Cross scores:', cross_score)\n",
    "print('Stdev:', np.std(cross_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With (25,100) hidden layers, this model is much improved but if you look at the times for this model vs the random forest, it would take many more hidden layers for this neural network and would be incredibly slow. It is already much slower than the random forest and less effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
